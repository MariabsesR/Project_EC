{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324313d5",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49511d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, SequentialFeatureSelector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix, f1_score, matthews_corrcoef, mean_squared_error, mean_absolute_error, precision_score, r2_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6469d394",
   "metadata": {},
   "source": [
    "## All unecessary prints have been commented instead of removed, as the teacher may find the need to see them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e46d376",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "caa87255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adles\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Data loading and transformation of ? and diagnoses classes\n",
    "\n",
    "def preprocess_data(*args):\n",
    "    if len(args) == 1:\n",
    "        raw_data_file = args[0]\n",
    "        data = pd.read_csv(raw_data_file)\n",
    "    elif len(args) == 2:\n",
    "        raw_data_file = args[0]\n",
    "        additional_data_file = args[1]\n",
    "        data = pd.read_csv(raw_data_file)\n",
    "        additional_data = pd.read_csv(additional_data_file)\n",
    "        additional_column = additional_data.columns[0].rstrip(':')\n",
    "        data = pd.concat([data, additional_data], axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"The function accepts either one or two arguments.\")\n",
    "    \n",
    "    # Replace the current diagnoses to the classes desired \n",
    "    class_mapping = {\n",
    "        'A': 'hyperthyroid conditions',\n",
    "        'B': 'hyperthyroid conditions',\n",
    "        'C': 'hyperthyroid conditions',\n",
    "        'D': 'hyperthyroid conditions',\n",
    "        'E': 'hypothyroid conditions',\n",
    "        'F': 'hypothyroid conditions',\n",
    "        'G': 'hypothyroid conditions',\n",
    "        'H': 'hypothyroid conditions',\n",
    "        'I': 'binding protein',\n",
    "        'J': 'binding protein',\n",
    "        'K': 'general health',\n",
    "        'L': 'replacement therapy',\n",
    "        'M': 'replacement therapy',\n",
    "        'N': 'replacement therapy',\n",
    "        'R': 'discordant results',\n",
    "        '-': 'healthy class' \n",
    "    }\n",
    "\n",
    "    # Helper function to map labels to their categories\n",
    "    def map_label_to_category(label):\n",
    "        return class_mapping.get(label, 'other class')\n",
    "    \n",
    "    # Map diagnoses to new categories \n",
    "    data['diagnoses'] = data['diagnoses'].apply(map_label_to_category)\n",
    "\n",
    "    # Check if we have the 8 needed classes after mapping \n",
    "    unique_diagnoses = data['diagnoses'].unique()\n",
    "    #print(\"Unique values in 'diagnoses' column:\")\n",
    "    #for value in unique_diagnoses:\n",
    "        #print(value)\n",
    "    \n",
    "    # Replace '?' with NaN to be able to see missing values in analysis \n",
    "    data.replace('?', np.nan, inplace=True)\n",
    "    df = pd.DataFrame(data)\n",
    "    #print(df.head())\n",
    "    \n",
    "    df.columns = df.columns.str.rstrip(':')\n",
    "    \n",
    "    # Encoder to transform the values of numbers that are being considered strings\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "    # Initialize OneHotEncoder for categorical columns\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    \n",
    "    # Deletion of impossible ages (<0 && >130)\n",
    "    top_10_biggest = df['age'].nlargest(10)\n",
    "    top_10_smallest = df['age'].nsmallest(10)\n",
    "    #print(\"Top 10 biggest ages before drop:\")\n",
    "    #print(top_10_biggest)\n",
    "    #print(\"\\nTop 10 smallest ages before drop\")\n",
    "    #print(top_10_smallest)\n",
    "\n",
    "    indices_to_drop_high = df[df['age'] > 130].index\n",
    "    indices_to_drop_low = df[df['age'] < 0].index\n",
    "\n",
    "    # Drop rows with ages greater than 130 and lower than 0 \n",
    "    df = df.drop(index=indices_to_drop_high).reset_index(drop=True)\n",
    "    df = df.drop(index=indices_to_drop_low).reset_index(drop=True)\n",
    "\n",
    "    # Check age after the drop \n",
    "    top_10_biggest = df['age'].nlargest(10)\n",
    "    top_10_smallest = df['age'].nsmallest(10)\n",
    "    #print(\"\\n\\nTop 10 biggest ages after dropping ages > 130:\")\n",
    "    #print(top_10_biggest)\n",
    "    #print(\"\\nTop 10 smallest ages after dropping ages < 0:\")\n",
    "    #print(top_10_smallest)\n",
    "\n",
    "\n",
    "    missing_sex_count = df['sex'].isnull().sum()\n",
    "    #print(\"Number of missing values in 'sex:' column:\", missing_sex_count)\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "    df['sex'] = imputer.fit_transform(df[['sex']]).flatten()\n",
    "    #print(\"Number of missing :\", df['sex'].isnull().sum())\n",
    "\n",
    "    # Drop unique column since it won't be used for analysis only for identification\n",
    "    df.drop(columns=['[record identification]'], inplace=True)\n",
    "\n",
    "    num_columns = ['age', 'TSH', 'T3', 'TT4', 'T4U', 'FTI', 'TBG']\n",
    "\n",
    "    trueORfalse_columns = ['on thyroxine', 'query on thyroxine', 'on antithyroid medication', \n",
    "                          'sick', 'pregnant', 'thyroid surgery', 'I131 treatment', 'query hypothyroid', \n",
    "                          'query hyperthyroid', 'lithium', 'goitre', 'tumor', 'hypopituitary', 'psych', \n",
    "                          'TSH measured', 'T3 measured', 'TT4 measured', 'T4U measured', 'FTI measured', \n",
    "                          'TBG measured']\n",
    "\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "    for column in trueORfalse_columns:\n",
    "        df[column] = imputer.fit_transform(df[[column]]).flatten()\n",
    "\n",
    "    for col in trueORfalse_columns:\n",
    "        df[col] = df[col].apply(lambda x: 1 if x == 't' else 0)\n",
    "\n",
    "    df['sex'] = df['sex'].apply(lambda x: 1 if x == 'F' else 0)\n",
    "\n",
    "    referral_encoder = OneHotEncoder(sparse=False)\n",
    "    referral_encoded = referral_encoder.fit_transform(df[['referral source']])\n",
    "    referral_feature_names = referral_encoder.get_feature_names_out(['referral source'])\n",
    "    referral_encoded_df = pd.DataFrame(referral_encoded, columns=referral_feature_names)\n",
    "\n",
    "    #print(referral_encoder.categories_)\n",
    "    df = pd.concat([df.drop(columns=['referral source']), referral_encoded_df], axis=1)\n",
    "    df[num_columns] = ordinal_encoder.fit_transform(df[num_columns])\n",
    "    \n",
    "    # As said and shown in the report, we tested multiple values and while there was not much difference, this one was slightly better\n",
    "    df.fillna(999, inplace=True)\n",
    "    #print(df.isnull().sum())\n",
    "    \n",
    "    if len(args) == 2:\n",
    "        return df.drop(columns=[additional_column]), df[additional_column]\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "# Check example of data \n",
    "df = preprocess_data('proj-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a8cd7c",
   "metadata": {},
   "source": [
    "# O1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65de939f",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73b4a5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-Fold Cross Validation Results:\n",
      "Precision: 0.8882428496198685\n",
      "Recall: 0.8921267893660532\n",
      "F1 Score: 0.8896319157706672\n",
      "Matthews Correlation Coefficient: 0.7535025292895594\n",
      "Balanced Accuracy: 0.7273518318466736\n",
      "Macro F1 Score: 0.7387937020573921\n",
      "Classification Report for N-Fold Cross Validation:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "        binding protein       0.63      0.51      0.57       230\n",
      "     discordant results       0.66      0.69      0.68       135\n",
      "         general health       0.81      0.87      0.84       274\n",
      "          healthy class       0.94      0.96      0.95      4324\n",
      "hyperthyroid conditions       0.72      0.69      0.71       111\n",
      " hypothyroid conditions       0.78      0.77      0.78       384\n",
      "            other class       0.61      0.50      0.55       189\n",
      "    replacement therapy       0.88      0.82      0.85       221\n",
      "\n",
      "               accuracy                           0.89      5868\n",
      "              macro avg       0.75      0.73      0.74      5868\n",
      "           weighted avg       0.89      0.89      0.89      5868\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def dtcO1(df_data, df_class=None):\n",
    "\n",
    "    # Instantiate Decision Tree classifier\n",
    "    dtc = DecisionTreeClassifier()\n",
    "\n",
    "    # Define Sequential Feature Selector with Decision Tree classifier\n",
    "    sfs = SequentialFeatureSelector(dtc, n_features_to_select=30, direction='forward')\n",
    "    \n",
    "    if df_class is None:\n",
    "        # Fit Sequential Feature Selector to data\n",
    "        sfs.fit(df_data.drop('diagnoses', axis=1), df_data['diagnoses'])\n",
    "    else:\n",
    "        # Fit Sequential Feature Selector to data\n",
    "        sfs.fit(df_data, df_class)\n",
    "    \n",
    "    \n",
    "    selected_features_indices = np.arange(len(sfs.get_support()))[sfs.get_support()]\n",
    "    \n",
    "    if df_class is None:\n",
    "        selected_columns = df_data.drop('diagnoses', axis=1).columns[selected_features_indices]\n",
    "        \n",
    "        # Transform the data based on selected features\n",
    "        selected_features_train = sfs.transform(df_data.drop('diagnoses', axis=1))\n",
    "        target = df_data['diagnoses']\n",
    "        \n",
    "    else:\n",
    "        selected_columns = df_data.columns[selected_features_indices]\n",
    "        \n",
    "        # Transform the data based on selected features\n",
    "        selected_features_train = sfs.transform(df_data)\n",
    "        target = df_class\n",
    "\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(selected_features_train, target, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    # Hyperparameter tuning with GridSearchCV\n",
    "    param_grid = {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'splitter': ['best', 'random'],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': [None, 'sqrt', 'log2'],\n",
    "        'random_state': [42]\n",
    "    }\n",
    "\n",
    "    clf_grid = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=param_grid, cv=5)\n",
    "\n",
    "    # N-Fold Cross Validation, separa os dados de forma a tesra com todos quais seriam os melhores de teste etc \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    kf.get_n_splits(X_train)\n",
    "\n",
    "    TRUTH_nfold = None\n",
    "    PREDS_nfold = None\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[test_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Train the model with the best parameters\n",
    "        clf_grid.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        best_clf = clf_grid.best_estimator_\n",
    "        best_clf.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Make predictions\n",
    "        preds = best_clf.predict(X_val_fold)\n",
    "\n",
    "        if TRUTH_nfold is None:\n",
    "            PREDS_nfold = preds\n",
    "            TRUTH_nfold = y_val_fold\n",
    "        else:\n",
    "            PREDS_nfold = np.hstack((PREDS_nfold, preds))\n",
    "            TRUTH_nfold = np.hstack((TRUTH_nfold, y_val_fold))\n",
    "\n",
    "    # Evaluation metrics\n",
    "    precision = precision_score(TRUTH_nfold, PREDS_nfold, average='weighted')\n",
    "    recall = recall_score(TRUTH_nfold, PREDS_nfold, average='weighted')\n",
    "    f1 = f1_score(TRUTH_nfold, PREDS_nfold, average='weighted')\n",
    "    mcc = matthews_corrcoef(TRUTH_nfold, PREDS_nfold)\n",
    "    balanced_accuracy = balanced_accuracy_score(TRUTH_nfold, PREDS_nfold)\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print(\"N-Fold Cross Validation Results:\")\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Matthews Correlation Coefficient:\", mcc)\n",
    "    print(\"Balanced Accuracy:\", balanced_accuracy)\n",
    "\n",
    "    # Calculate macro F1 score\n",
    "    f1_macro = f1_score(TRUTH_nfold, PREDS_nfold, average='macro')\n",
    "\n",
    "    # Print macro F1 score\n",
    "    print(\"Macro F1 Score:\", f1_macro)\n",
    "\n",
    "    #using nfold\n",
    "    # Generate classification report using mapped classes\n",
    "    print(\"Classification Report for N-Fold Cross Validation:\")\n",
    "    print(classification_report(TRUTH_nfold, PREDS_nfold,zero_division=1))\n",
    "    \n",
    "df_copy = dtcO1(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0d27ae",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d4bfbdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is:  0.8208\n",
      "The Precision is:  0.8300\n",
      "The Recall is:  0.8208\n",
      "The F1 score is:  0.8226\n",
      "The Matthews correlation coefficient is:  0.5792\n",
      "The Macro F1 Score is: 0.5607644608422453\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "        binding protein       0.60      0.46      0.52        54\n",
      "     discordant results       0.50      0.25      0.33        28\n",
      "         general health       0.61      0.53      0.57        72\n",
      "          healthy class       0.91      0.91      0.91      1102\n",
      "hyperthyroid conditions       0.67      0.45      0.54        31\n",
      " hypothyroid conditions       0.72      0.83      0.77        92\n",
      "            other class       0.18      0.38      0.25        34\n",
      "    replacement therapy       0.65      0.56      0.60        55\n",
      "\n",
      "               accuracy                           0.82      1468\n",
      "              macro avg       0.60      0.55      0.56      1468\n",
      "           weighted avg       0.83      0.82      0.82      1468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_copy = df.copy()\n",
    "\n",
    "X = df_copy.drop(columns=['diagnoses'])\n",
    "y = df_copy['diagnoses']\n",
    "\n",
    "\n",
    "X_df0 = df_copy.drop(columns=['diagnoses'])\n",
    "X_df= pd.get_dummies(X_df0, drop_first=True)\n",
    "X_df.columns=X_df0.columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "mdl=CategoricalNB(alpha=0.001)\n",
    "\n",
    "mdl.fit(X_train,y_train);\n",
    "\n",
    "\n",
    "# Predict on test data\n",
    "preds = mdl.predict(X_test)\n",
    "\n",
    "def printClassResults(truth, preds):\n",
    "    print(\"The Accuracy is: %7.4f\" % accuracy_score(truth, preds))\n",
    "    print(\"The Precision is: %7.4f\" % precision_score(truth, preds, average='weighted'))  # Change average to 'weighted'\n",
    "    print(\"The Recall is: %7.4f\" % recall_score(truth, preds, average='weighted'))  # Change average to 'weighted'\n",
    "    print(\"The F1 score is: %7.4f\" % f1_score(truth, preds, average='weighted'))  # Change average to 'weighted'\n",
    "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(truth, preds))\n",
    "    print(\"The Macro F1 Score is:\", f1_score(truth, preds, average='macro'))\n",
    "\n",
    "\n",
    "\n",
    "# Print the classification results\n",
    "printClassResults(y_test, preds)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186248a4",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b992d852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bias is:  0.5785134159001989\n",
      "The Accuracy is:  0.2732\n",
      "The Precision is:  0.7523\n",
      "The Recall is:  0.2732\n",
      "The F1 score is:  0.2672\n",
      "The Matthews correlation coefficient is:  0.2529\n",
      "The Macro F1 Score is:  0.2826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.57      0.39        54\n",
      "           1       0.03      0.29      0.06        28\n",
      "           2       0.21      0.74      0.33        72\n",
      "           3       0.93      0.14      0.25      1102\n",
      "           4       0.16      0.87      0.26        31\n",
      "           5       0.26      0.65      0.38        92\n",
      "           6       0.11      0.32      0.17        34\n",
      "           7       0.28      0.96      0.43        55\n",
      "\n",
      "    accuracy                           0.27      1468\n",
      "   macro avg       0.28      0.57      0.28      1468\n",
      "weighted avg       0.75      0.27      0.27      1468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a copy\n",
    "df_copy = df.copy()\n",
    "\n",
    "# Filter columns with numeric data types\n",
    "numeric_columns = df_copy.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# Filter columns with non-numeric data types\n",
    "non_numeric_columns = df_copy.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "# Print the list of numeric and non-numeric columns\n",
    "#print(\"Numeric Columns:\")\n",
    "#print(numeric_columns)\n",
    "#print(\"\\nNon-Numeric Columns:\")\n",
    "#print(non_numeric_columns)\n",
    "\n",
    "# Encode the 'diagnoses' column\n",
    "label_encoder = LabelEncoder()\n",
    "df_copy['diagnoses'] = label_encoder.fit_transform(df_copy['diagnoses'])\n",
    "\n",
    "# Define your features (X) and target variable (y)\n",
    "X = df_copy[numeric_columns]  # Features excluding the target column\n",
    "y = df_copy['diagnoses']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # Fit scaler on training set\n",
    "X_train = scaler.transform(X_train)  # Apply scaler on training set\n",
    "X_test = scaler.transform(X_test)  # Apply scaler on test set\n",
    "\n",
    "# Initialize logistic regression model with increased iterations and class weights\n",
    "mdl = LogisticRegression(random_state=0, max_iter=1000, class_weight='balanced').fit(X_train, y_train)\n",
    "\n",
    "print(\"The bias is: \",  mdl.intercept_[0])\n",
    "#print(\"The other parameters are: \")\n",
    "#for i, beta in enumerate(mdl.coef_[0]):\n",
    "#    print(\"\\t B%02d -> %9.3f\" % (i+1, beta))\n",
    "\n",
    "coefs = [(beta, i) for i, beta in enumerate(mdl.coef_[0])]\n",
    "coefss = sorted(coefs, key=lambda row: np.abs(row[0]))\n",
    "coefss.reverse()\n",
    "#for beta, i in coefss[:5]:\n",
    "#    print(\"\\t B%02d -> %9.3f\" % (i+1, beta))\n",
    "\n",
    "def printClassResults(truth, preds):\n",
    "    print(\"The Accuracy is: %7.4f\" % accuracy_score(truth, preds))\n",
    "    print(\"The Precision is: %7.4f\" % precision_score(truth, preds, average='weighted', zero_division=0))\n",
    "    print(\"The Recall is: %7.4f\" % recall_score(truth, preds, average='weighted', zero_division=0))\n",
    "    print(\"The F1 score is: %7.4f\" % f1_score(truth, preds, average='weighted', zero_division=0))\n",
    "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(truth, preds))\n",
    "    print(\"The Macro F1 Score is: %7.4f\" % f1_score(truth, preds, average='macro', zero_division=0))\n",
    "\n",
    "preds = mdl.predict(X_test)\n",
    "\n",
    "printClassResults(y_test, preds)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65462a16",
   "metadata": {},
   "source": [
    "# O2 - SEX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275fcdf6",
   "metadata": {},
   "source": [
    "## Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e56cdbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-Fold Cross Validation Results:\n",
      "Precision: 0.6516835434366557\n",
      "Recall: 0.6872869802317655\n",
      "F1 Score: 0.6454349036248204\n",
      "Matthews Correlation Coefficient: 0.17125061486140866\n",
      "Balanced Accuracy: 0.5642392010332995\n",
      "Macro F1 Score: 0.5571487048782046\n",
      "Classification Report for N-Fold Cross Validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.23      0.32      1855\n",
      "           1       0.72      0.90      0.80      4013\n",
      "\n",
      "    accuracy                           0.69      5868\n",
      "   macro avg       0.61      0.56      0.56      5868\n",
      "weighted avg       0.65      0.69      0.65      5868\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sexO2(df_data, df_class=None):\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    # Encode the 'diagnoses' column\n",
    "    df_data['diagnoses'] = label_encoder.fit_transform(df_data['diagnoses'])\n",
    "    \n",
    "    if df_class is None:\n",
    "        # Split data into features and target\n",
    "        X = df_data.drop(columns=['sex'])\n",
    "        y = df_data['sex']\n",
    "    else:\n",
    "        # Split data into features and target\n",
    "        X = df_data\n",
    "        y = df_class\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Hyperparameter tuning with GridSearchCV\n",
    "    param_grid = {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'splitter': ['best', 'random'],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': [None, 'sqrt', 'log2'],\n",
    "        'random_state': [42]\n",
    "    }\n",
    "\n",
    "    clf_grid = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=param_grid, cv=5)\n",
    "\n",
    "    # N-Fold Cross Validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    kf.get_n_splits(X_train)\n",
    "\n",
    "    # Initialize lists to store predictions and true labels\n",
    "    all_PREDS = []\n",
    "    all_TRUTH = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        # Train the model with the best parameters\n",
    "        clf_grid.fit(X_train_fold, y_train_fold)\n",
    "        best_clf = clf_grid.best_estimator_\n",
    "        best_clf.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Make predictions\n",
    "        preds = best_clf.predict(X_val_fold)\n",
    "\n",
    "        # Append predictions and true labels to the lists\n",
    "        all_PREDS.append(preds)\n",
    "        all_TRUTH.append(y_val_fold)\n",
    "\n",
    "    # Concatenate predictions and true labels vertically\n",
    "    PREDS_nfold = np.concatenate(all_PREDS)\n",
    "    TRUTH_nfold = np.concatenate(all_TRUTH)\n",
    "\n",
    "    # Evaluation metrics\n",
    "    precision = precision_score(TRUTH_nfold, PREDS_nfold, average='weighted')\n",
    "    recall = recall_score(TRUTH_nfold, PREDS_nfold, average='weighted')\n",
    "    f1 = f1_score(TRUTH_nfold, PREDS_nfold, average='weighted')\n",
    "    mcc = matthews_corrcoef(TRUTH_nfold, PREDS_nfold)\n",
    "    balanced_accuracy = balanced_accuracy_score(TRUTH_nfold, PREDS_nfold)\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print(\"N-Fold Cross Validation Results:\")\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Matthews Correlation Coefficient:\", mcc)\n",
    "    print(\"Balanced Accuracy:\", balanced_accuracy)\n",
    "\n",
    "    # Calculate and print macro F1 score\n",
    "    f1_macro = f1_score(TRUTH_nfold, PREDS_nfold, average='macro')\n",
    "    print(\"Macro F1 Score:\", f1_macro)\n",
    "\n",
    "\n",
    "    # Using nfold\n",
    "    # Generate classification report using mapped classes\n",
    "    print(\"Classification Report for N-Fold Cross Validation:\")\n",
    "    print(classification_report(TRUTH_nfold, PREDS_nfold, zero_division=1))\n",
    "\n",
    "df_O2SEX = sexO2(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6857244d",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40c28ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is:  0.6655\n",
      "The Precision is:  0.6986\n",
      "The Recall is:  0.6655\n",
      "The F1 score is:  0.6779\n",
      "The Matthews correlation coefficient is:  0.2270\n",
      "The Macro F1 Score is: 0.6083318888248295\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.53      0.46       393\n",
      "           1       0.81      0.72      0.76      1075\n",
      "\n",
      "    accuracy                           0.67      1468\n",
      "   macro avg       0.61      0.62      0.61      1468\n",
      "weighted avg       0.70      0.67      0.68      1468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_copySex = df.copy()\n",
    "\n",
    "# Encode the 'diagnoses' column\n",
    "label_encoder = LabelEncoder()\n",
    "df_copySex['diagnoses'] = label_encoder.fit_transform(df_copySex['diagnoses'])\n",
    "\n",
    "X = df_copySex.drop(columns=['sex'])\n",
    "y = df_copySex['sex']\n",
    "\n",
    "X_df0 = df_copySex.drop(columns=['sex'])\n",
    "X_df= pd.get_dummies(X_df0, drop_first=True)\n",
    "X_df.columns=X_df0.columns\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "mdl=CategoricalNB(alpha=0.001)\n",
    "\n",
    "mdl.fit(X_train,y_train);\n",
    "\n",
    "# Predict on test data\n",
    "preds = mdl.predict(X_test)\n",
    "\n",
    "def printClassResults(truth, preds):\n",
    "    print(\"The Accuracy is: %7.4f\" % accuracy_score(truth, preds))\n",
    "    print(\"The Precision is: %7.4f\" % precision_score(truth, preds, average='weighted'))\n",
    "    print(\"The Recall is: %7.4f\" % recall_score(truth, preds, average='weighted'))\n",
    "    print(\"The F1 score is: %7.4f\" % f1_score(truth, preds, average='weighted'))\n",
    "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(truth, preds))\n",
    "    print(\"The Macro F1 Score is:\", f1_score(truth, preds, average='macro'))\n",
    "\n",
    "\n",
    "# Print the classification results\n",
    "printClassResults(y_test, preds)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9c7549",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "113c1dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bias is:  0.20796506873354198\n",
      "The other parameters are: \n",
      "The Accuracy is:  0.6233\n",
      "The Precision is:  0.7034\n",
      "The Recall is:  0.6233\n",
      "The F1 score is:  0.6443\n",
      "The Matthews correlation coefficient is:  0.2254\n",
      "The Macro F1 Score is: 0.5902328715609991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.63      0.47       393\n",
      "           1       0.82      0.62      0.71      1075\n",
      "\n",
      "    accuracy                           0.62      1468\n",
      "   macro avg       0.60      0.63      0.59      1468\n",
      "weighted avg       0.70      0.62      0.64      1468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_copySex = df.copy()\n",
    "\n",
    "# Encode the 'diagnoses' column\n",
    "label_encoder = LabelEncoder()\n",
    "df_copySex['diagnoses'] = label_encoder.fit_transform(df_copySex['diagnoses'])\n",
    "\n",
    "# Define your features (X) and target variable (y)\n",
    "X = df_copySex[numeric_columns].drop('sex', axis=1)  # Features excluding the target column\n",
    "y = df_copySex['sex']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # Fit scaler on training set\n",
    "X_train = scaler.transform(X_train)  # Apply scaler on training set\n",
    "X_test = scaler.transform(X_test)  # Apply scaler on test set\n",
    "\n",
    "# Initialize logistic regression model with increased iterations and class weights\n",
    "mdl = LogisticRegression(random_state=0, max_iter=1000, class_weight='balanced').fit(X_train, y_train)\n",
    "\n",
    "print(\"The bias is: \",  mdl.intercept_[0])\n",
    "print(\"The other parameters are: \")\n",
    "#for i, beta in enumerate(mdl.coef_[0]):\n",
    "    #print(\"\\t B%02d -> %9.3f\" % (i+1, beta))\n",
    "\n",
    "coefs = [(beta, i) for i, beta in enumerate(mdl.coef_[0])]\n",
    "coefss = sorted(coefs, key=lambda row: np.abs(row[0]))\n",
    "coefss.reverse()\n",
    "#for beta, i in coefss[:5]:\n",
    "    #print(\"\\t B%02d -> %9.3f\" % (i+1, beta))\n",
    "\n",
    "\n",
    "# Predict on test data\n",
    "preds = mdl.predict(X_test)\n",
    "\n",
    "def printClassResults(truth, preds):\n",
    "    print(\"The Accuracy is: %7.4f\" % accuracy_score(truth, preds))\n",
    "    print(\"The Precision is: %7.4f\" % precision_score(truth, preds, average='weighted'))\n",
    "    print(\"The Recall is: %7.4f\" % recall_score(truth, preds, average='weighted'))\n",
    "    print(\"The F1 score is: %7.4f\" % f1_score(truth, preds, average='weighted'))\n",
    "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(truth, preds))\n",
    "    print(\"The Macro F1 Score is:\", f1_score(truth, preds, average='macro'))\n",
    "\n",
    "\n",
    "# Print the classification results\n",
    "printClassResults(y_test, preds)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383af7a8",
   "metadata": {},
   "source": [
    "# O2 - AGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cf7565",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d073749",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Average Evaluation Metrics across Folds:\n",
      "Average Mean Squared Error: 312.65632449027817\n",
      "Average Mean Absolute Error: 14.633386196185375\n",
      "Average R-squared Score: 0.12002259639729909\n"
     ]
    }
   ],
   "source": [
    "def ageO2(df_data, df_class=None):\n",
    "\n",
    "    # Encode the diafgnoses variable\n",
    "    label_encoder = LabelEncoder()\n",
    "    df_data['diagnoses'] = label_encoder.fit_transform(df_data['diagnoses'])\n",
    "\n",
    "    if df_class is None:\n",
    "        # Split data into features and target\n",
    "        X = df_data.drop(columns=['age'])\n",
    "        y = df_data['age']\n",
    "    else:\n",
    "        # Split data into features and target\n",
    "        X = df_data\n",
    "        y = df_class\n",
    "\n",
    "    # Initialize the Decision Tree Regressor\n",
    "    dt_regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "    # Initialize Sequential Feature Selector (SFS)\n",
    "    sfs = SequentialFeatureSelector(dt_regressor, n_features_to_select=30, direction='forward')\n",
    "\n",
    "    # Fit SFS to data\n",
    "    sfs.fit(X, y)\n",
    "\n",
    "    # Get selected features indices\n",
    "    selected_features_indices = sfs.get_support(indices=True)\n",
    "\n",
    "    # Filter X with selected features\n",
    "    X_selected = X.iloc[:, selected_features_indices]\n",
    "\n",
    "    # Define hyperparameters grid for grid search\n",
    "    param_grid = {\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    # Perform N-Fold Cross Validation with grid search\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    mse_scores = []\n",
    "    mae_scores = []\n",
    "    r2_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_selected):\n",
    "        X_train, X_test = X_selected.iloc[train_index], X_selected.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        grid_search = GridSearchCV(estimator=dt_regressor, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        best_params = grid_search.best_params_\n",
    "\n",
    "        best_dt_regressor = DecisionTreeRegressor(**best_params, random_state=42)\n",
    "        best_dt_regressor.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = best_dt_regressor.predict(X_test)\n",
    "\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        mse_scores.append(mse)\n",
    "        mae_scores.append(mae)\n",
    "        r2_scores.append(r2)\n",
    "\n",
    "    # Calculate average scores\n",
    "    avg_mse = sum(mse_scores) / len(mse_scores)\n",
    "    avg_mae = sum(mae_scores) / len(mae_scores)\n",
    "    avg_r2 = sum(r2_scores) / len(r2_scores)\n",
    "\n",
    "    # Print average evaluation metrics\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    print(\"Average Evaluation Metrics across Folds:\")\n",
    "    print(\"Average Mean Squared Error:\", avg_mse)\n",
    "    print(\"Average Mean Absolute Error:\", avg_mae)\n",
    "    print(\"Average R-squared Score:\", avg_r2)\n",
    "    \n",
    "df_O2AGE = ageO2(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bac94a6",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a8caa55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is:  0.0218\n",
      "The Precision is:  0.0243\n",
      "The Recall is:  0.0218\n",
      "The F1 Score is:  0.0225\n",
      "The Matthews Correlation Coefficient is:  0.0067\n",
      "The Macro F1 Score is:  0.0146\n"
     ]
    }
   ],
   "source": [
    "df_copyAge = df.copy()\n",
    "\n",
    "# Encode the 'diagnoses' column\n",
    "label_encoder = LabelEncoder()\n",
    "df_copyAge['diagnoses'] = label_encoder.fit_transform(df_copyAge['diagnoses'])\n",
    "\n",
    "X = df_copyAge.drop(columns=['age'])\n",
    "\n",
    "y = df_copyAge['age']\n",
    "\n",
    "X_df0 = df_copyAge.drop(columns=['age'])\n",
    "X_df= pd.get_dummies(X_df0, drop_first=True)\n",
    "X_df.columns=X_df0.columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "mdl=CategoricalNB(alpha=0.001)\n",
    "\n",
    "mdl.fit(X_train,y_train);\n",
    "\n",
    "# Predict on test data\n",
    "preds = mdl.predict(X_test)\n",
    "\n",
    "# Define a function to print classification results\n",
    "def printClassResults(truth, preds):\n",
    "    print(\"The Accuracy is: %7.4f\" % accuracy_score(truth, preds))\n",
    "    print(\"The Precision is: %7.4f\" % precision_score(truth, preds, average='weighted', zero_division=0))\n",
    "    print(\"The Recall is: %7.4f\" % recall_score(truth, preds, average='weighted', zero_division=0))\n",
    "    print(\"The F1 Score is: %7.4f\" % f1_score(truth, preds, average='weighted', zero_division=0))\n",
    "    print(\"The Matthews Correlation Coefficient is: %7.4f\" % matthews_corrcoef(truth, preds))\n",
    "    print(\"The Macro F1 Score is: %7.4f\" % f1_score(truth, preds, average='macro', zero_division=0))\n",
    "\n",
    "\n",
    "# Print the classification results\n",
    "printClassResults(y_test, preds)\n",
    "\n",
    "# Print the classification report\n",
    "#print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d88da5",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a9d914c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bias is:  -0.6768203866153133\n",
      "The other parameters are: \n",
      "The Accuracy is:  0.0089\n",
      "The Precision is:  0.0140\n",
      "The Recall is:  0.0089\n",
      "The F1 Score is:  0.0073\n",
      "The Matthews Correlation Coefficient is:  0.0046\n",
      "The Macro F1 Score is:  0.0083\n"
     ]
    }
   ],
   "source": [
    "df_copyAge = df.copy()\n",
    "\n",
    "# Encode the 'diagnoses' column\n",
    "label_encoder = LabelEncoder()\n",
    "df_copyAge['diagnoses'] = label_encoder.fit_transform(df_copyAge['diagnoses'])\n",
    "\n",
    "# Define your features (X) and target variable (y)\n",
    "X = df_copyAge[numeric_columns].drop('age', axis=1)  # Features excluding the target column\n",
    "y = df_copyAge['age']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # Fit scaler on training set\n",
    "X_train = scaler.transform(X_train)  # Apply scaler on training set\n",
    "X_test = scaler.transform(X_test)  # Apply scaler on test set\n",
    "\n",
    "# Initialize logistic regression model with increased iterations and class weights\n",
    "mdl = LogisticRegression(random_state=0, max_iter=1000, class_weight='balanced').fit(X_train, y_train)\n",
    "\n",
    "print(\"The bias is: \",  mdl.intercept_[0])\n",
    "print(\"The other parameters are: \")\n",
    "#for i, beta in enumerate(mdl.coef_[0]):\n",
    "    #print(\"\\t B%02d -> %9.3f\" % (i+1, beta))\n",
    "\n",
    "coefs = [(beta, i) for i, beta in enumerate(mdl.coef_[0])]\n",
    "coefss = sorted(coefs, key=lambda row: np.abs(row[0]))\n",
    "coefss.reverse()\n",
    "#for beta, i in coefss[:5]:\n",
    "    #print(\"\\t B%02d -> %9.3f\" % (i+1, beta))\n",
    "\n",
    "\n",
    "# Predict on test data\n",
    "preds = mdl.predict(X_test)\n",
    "\n",
    "# Define a function to print classification results\n",
    "def printClassResults(truth, preds):\n",
    "    print(\"The Accuracy is: %7.4f\" % accuracy_score(truth, preds))\n",
    "    print(\"The Precision is: %7.4f\" % precision_score(truth, preds, average='weighted', zero_division=0))\n",
    "    print(\"The Recall is: %7.4f\" % recall_score(truth, preds, average='weighted', zero_division=0))\n",
    "    print(\"The F1 Score is: %7.4f\" % f1_score(truth, preds, average='weighted', zero_division=0))\n",
    "    print(\"The Matthews Correlation Coefficient is: %7.4f\" % matthews_corrcoef(truth, preds))\n",
    "    print(\"The Macro F1 Score is: %7.4f\" % f1_score(truth, preds, average='macro', zero_division=0))\n",
    "\n",
    "\n",
    "# Print the classification results\n",
    "printClassResults(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19d08ff",
   "metadata": {},
   "source": [
    "# O3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14183c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Columns: ['on antithyroid medication', 'pregnant', 'thyroid surgery', 'hypopituitary', 'TSH measured', 'TSH', 'TT4 measured', 'TBG measured', 'TBG', 'referral source_WEST']\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------O3-------------------------------------------------------\n",
    "df_copy = df.copy()\n",
    "#------------------------------------only for analysis \n",
    "# Instantiate Decision Tree classifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "# Define Sequential Feature Selector with Decision Tree classifier\n",
    "sfs = SequentialFeatureSelector(dtc, n_features_to_select=10, direction='forward')\n",
    "\n",
    "# Fit Sequential Feature Selector to data\n",
    "sfs.fit(df_copy.drop('diagnoses', axis=1), df_copy['diagnoses'])\n",
    "selected_features_indices = np.arange(len(sfs.get_support()))[sfs.get_support()]\n",
    "selected_columns = df_copy.drop('diagnoses', axis=1).columns[selected_features_indices]\n",
    "\n",
    "# Print the names of the selected columns\n",
    "print(\"Selected Columns:\", selected_columns.tolist())\n",
    "# Transform the data based on selected features\n",
    "selected_features_train = sfs.transform(df_copy.drop('diagnoses', axis=1))\n",
    "target = df_copy['diagnoses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e9141b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Columns: ['query on thyroxine', 'pregnant', 'thyroid surgery', 'lithium', 'goitre', 'hypopituitary', 'TT4 measured', 'diagnoses', 'referral source_STMW', 'referral source_SVHC']\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------feature analysis sex O3--------------------------------------------------- \n",
    "df_copySex=df.copy()\n",
    "# Encode the 'diagnoses' column\n",
    "label_encoder = LabelEncoder()\n",
    "df_copySex['diagnoses'] = label_encoder.fit_transform(df_copySex['diagnoses'])\n",
    "\n",
    "# Define Sequential Feature Selector with Decision Tree classifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "sfs = SequentialFeatureSelector(dtc, n_features_to_select=10, direction='forward')\n",
    "\n",
    "# Fit Sequential Feature Selector to data\n",
    "sfs.fit(df_copySex.drop('sex', axis=1), df_copySex['sex'])\n",
    "selected_features_indices = np.arange(len(sfs.get_support()))[sfs.get_support()]\n",
    "selected_columns = df_copySex.drop('sex', axis=1).columns[selected_features_indices]\n",
    "\n",
    "# Print the names of the selected columns\n",
    "print(\"Selected Columns:\", selected_columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d27b6d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Columns by SFS: ['sick', 'I131 treatment', 'goitre', 'hypopituitary', 'TSH measured', 'T3 measured', 'T3', 'referral source_STMW', 'referral source_SVI', 'referral source_WEST']\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------feature analysis O3 Age-------------------------------------------\n",
    "\n",
    "# Copy DataFrame\n",
    "df_copyAge = df.copy()\n",
    "\n",
    "# Encode the 'diagnoses' column\n",
    "label_encoder = LabelEncoder()\n",
    "df_copyAge['diagnoses'] = label_encoder.fit_transform(df_copyAge['diagnoses'])\n",
    "\n",
    "# Define Sequential Feature Selector with Decision Tree Regressor\n",
    "dtr = DecisionTreeRegressor()\n",
    "sfs = SequentialFeatureSelector(dtr, n_features_to_select=10, direction='forward')\n",
    "\n",
    "# Fit Sequential Feature Selector to data\n",
    "sfs.fit(df_copyAge.drop('age', axis=1), df_copyAge['age'])\n",
    "selected_features_indices = np.arange(len(sfs.get_support()))[sfs.get_support()]\n",
    "selected_columns = df_copyAge.drop('age', axis=1).columns[selected_features_indices]\n",
    "\n",
    "# Print the names of the selected columns\n",
    "print(\"Selected Columns by SFS:\", selected_columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd62252",
   "metadata": {},
   "source": [
    "# CELL FOR RUNNING BY TEACHER (DEMORA 10+/- min):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c691def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We realized on the last day that this was supposed to do, was train the model with the proj-data.csv. Instead, we are\n",
    "#training the models with the given test files. When we realized it there was no time to change it, therefore even though\n",
    "#we know it is incorrect we are sending it as is as this was all we could do in the time we had.\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# O1\n",
    "print(\"O1:\\n\")\n",
    "df_data, df_class = preprocess_data('proj-test-data.csv', 'proj-test-class.csv')\n",
    "df_dtc = dtcO1(df_data, df_class)\n",
    "\n",
    "# O2 - Age\n",
    "print(\"\\n\\n\\nO2 - Age:\\n\")\n",
    "df_dataAge, df_classAge = preprocess_data('test2-data.csv', 'test2-age.csv')\n",
    "df_dtcAge = ageO2(df_dataAge, df_classAge)\n",
    "\n",
    "# O2 - Sex\n",
    "print(\"\\n\\n\\nO2 - Sex:\\n\")\n",
    "df_dataSex, df_classSex = preprocess_data('test3-data.csv', 'test3-sex.csv')\n",
    "df_dtcSex = sexO2(df_dataSex, df_classSex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
